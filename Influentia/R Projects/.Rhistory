MONTH = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[2])
) %>%
select(-DATE),
by = c("YEAR", "MONTH")
) %>%
mutate(
RESPONSE = lead(ILITOTAL, n = 1)
) %>%
select(ILITOTAL, `TOTAL PATIENTS`, PRCP, SNOW, TAVG, RESPONSE)
test  <- train[391:397, ]
train <- train[1:390, ]
# Regression Model ----
model <- glm(RESPONSE ~ ., data = train)
model
plot(model)
prediction <- as.integer(predict(model, newdata = test[, 1:5]))
library(caret)
# Metrics ----
RMSE(prediction, test$RESPONSE, na.rm = TRUE)
prediction
test$RESPONSE
library(tidyverse)
library(ggplot2)
library(scales)
library(lubridate)
library(caret)
colorado_weather <- read_csv('input/Colorado-Station-Report.csv') %>%
select(-STATION, -NAME)
ilinet_colorado <- readRDS('data/train.rds') %>%
filter(REGION == 'Colorado')
colorado_weather %>%
select(-DATE) %>%
mutate_all(
funs(rescale, "rescale", rescale(., to = c(0, 1)))
) %>%
select(contains('rescale')) %>%
ts.plot(col = c('blue', 'red', 'green'))
ilinet_colorado %>%
select(-REGION, -YEAR, -WEEK, -YEARWEEK, -PRETTYDATE) %>%
mutate_all(
funs(rescale, "rescale", rescale(., to = c(0, 1)))
) %>%
select(contains('rescale')) %>%
ts.plot(col = c('blue', 'red', 'green', 'black'))
train <- ilinet_colorado %>%
mutate(
MONTH = lubridate::month(PRETTYDATE)
) %>%
left_join(
colorado_weather %>%
rowwise() %>%
mutate(
YEAR  = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[1]),
MONTH = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[2])
) %>%
select(-DATE),
by = c("YEAR", "MONTH")
) %>%
mutate(
RESPONSE = lead(ILITOTAL, n = 1)
) %>%
select(ILITOTAL, `TOTAL PATIENTS`, PRCP, SNOW, TAVG, RESPONSE)
test  <- train[391:397, ]
train <- train[1:390, ]
model <- glm(RESPONSE ~ ., data = train)
prediction <- as.integer(predict(model, newdata = test[, 1:5]))
# Metrics ----
RMSE(prediction, test$RESPONSE, na.rm = TRUE)
print(prediction)
print(test$RESPONSE)
# Libraries ----
library(tidyverse)
library(magrittr)
# setwd('Documents/dev/Lepus/Influentia/R Projects/')
# Data Loading ----
# Working with ilinet only as the table broke by age group doesn't have State info
ilinet_tbl  <- read_csv('input/ILINet.csv') %>%
arrange(REGION, YEAR, WEEK)
# Preprocessing ----
# Check number of unique values per feature
map(ilinet_tbl, ~length(unique(.x)))
# Drop irrelevant features
ilinet_tbl <- ilinet_tbl[, map_lgl(ilinet_tbl, ~length(unique(.x)) > 2)]
# Investigate why WEEK has 53 distinct values (a year has 52 weeks)
table(ilinet_tbl$WEEK)
# TODO verify what is the week 53 (maybe leap year?), dropping for now
ilinet_tbl %<>%
filter(WEEK != 53)
# Coerce numerical features to numeric (this will introduce NAs where value == 'X')
ilinet_tbl[, 4:7] <- map(ilinet_tbl[, 4:7], as.numeric)
# Check number of NAs per feature
ilinet_tbl %>%
group_by(REGION) %>%
summarise_all(function(x){sum(is.na(x))}) %>%
View
# NAs are mostly divided between Florida and Virgin Islands, let's
# investigate further
ilinet_tbl %>%
filter(REGION %in% c('Florida', 'Virgin Islands')) %>%
group_by(REGION) %>%
summarise_all(function(x){sum(is.na(x))/length(x)}) %>%
View
# 100% of Florida info is NA, 60% of Virgin Islands info is NA
# TODO decide what to do with these states later, dropping for now
ilinet_tbl %<>%
filter(!(REGION %in% c('Florida', 'Virgin Islands')))
# Combine YEAR and WEEK info
ilinet_tbl %<>%
mutate(
YEARWEEK   = paste(YEAR, WEEK, sep = '-'),
PRETTYDATE = as.Date(paste(YEAR, WEEK, 1, sep="-"), "%Y-%U-%u")
)
# Train/Test split ----
# Use last 3 weeks as Test Set (as data is released w/ 2 weeks lag + 1 week protection
# against data release delay)
train <- ilinet_tbl %>%
filter(PRETTYDATE < max(PRETTYDATE) - lubridate::weeks(3))
test <- ilinet_tbl %>%
filter(PRETTYDATE >= max(PRETTYDATE) - lubridate::weeks(3))
# saveRDS(train, 'data/train.rds')
# saveRDS(test, 'data/test.rds')
# write_csv(train, 'data/train.csv')
# write_csv(test, 'data/test.csv')
train
print(train)
View(ilinet_tbl)
---
title: "ILINet Forecast"
output: html_notebook
---
## Setting up libraries
```{r}
library(forecast)
library(lubridate)
library(tidyverse)
library(prophet)
library(Metrics)
```
## Loading Train/Test data
```{r}
train <- readRDS('data/train.rds')
test  <- readRDS('data/test.rds')
```
## Data split by state for individual predictions
Assuming that different States have different behaviour regarding Flu cycles because of latitude and longitude differences, we'll fit a model to each one.
```{r tidy=FALSE}
data_split <- function(data){
data_sp <- lapply(
unique(data$REGION),
function(x) data[data$REGION == x,]
)
}
test_split  <- data_split(test)
train_split <- data_split(train)
```
## Forecasting
The Prophet library takes as input a dataframe with two variables: **ds** for the dates in the format YYYY-MM-DD and **y** for the numeric value.
```{r echo=T, results='hide', tidy=FALSE}
models_profet    <- list()
forecasts_profet <- list()
for(state_df in train_split){
model <-state_df %>%
select(ds = PRETTYDATE, y = ILITOTAL) %>%
prophet(
yearly.seasonality = TRUE,
weekly.seasonality = TRUE,
daily.seasonality = FALSE
)
future <- make_future_dataframe(
model,
periods = 4,
freq = 'week'
)
pred <- predict(model, future)
models_profet[unique(state_df$REGION)] <- list(model)
forecasts_profet[unique(state_df$REGION)] <- list(pred)
}
```
## Results (This function plots for the selected state)
```{r}
plot_forecast_prophet <- function(state){
plot(
models_profet[[state]],
forecasts_profet[[state]]
)
}
```
```{r}
plot_forecast_prophet('Montana')
```
## Forecasting using auto-arima since configure ARIMA one by one is difficult
ARIMA
```{r echo=T, results='hide', tidy=FALSE}
models_auto_arima    <- list()
forecasts_auto_arima <- list()
counter <-1
for(state_df in train_split){
model <-
auto.arima(
ts(state_df$ILITOTAL,
frequency=52,
start=decimal_date(ymd("2010-10-04")))
)
pred <- forecast(model,h=4)
models_auto_arima[unique(state_df$REGION)] <- list(model)
forecasts_auto_arima[unique(state_df$REGION)] <- list(pred)
}
library(forecast)
library(lubridate)
library(tidyverse)
library(prophet)
library(Metrics)
install.packages('Metrics')
library(forecast)
library(lubridate)
library(tidyverse)
library(prophet)
library(Metrics)
train <- readRDS('data/train.rds')
test  <- readRDS('data/test.rds')
data_split <- function(data){
data_sp <- lapply(
unique(data$REGION),
function(x) data[data$REGION == x,]
)
}
test_split  <- data_split(test)
train_split <- data_split(train)
models_profet    <- list()
forecasts_profet <- list()
for(state_df in train_split){
model <-state_df %>%
select(ds = PRETTYDATE, y = ILITOTAL) %>%
prophet(
yearly.seasonality = TRUE,
weekly.seasonality = TRUE,
daily.seasonality = FALSE
)
future <- make_future_dataframe(
model,
periods = 4,
freq = 'week'
)
pred <- predict(model, future)
models_profet[unique(state_df$REGION)] <- list(model)
forecasts_profet[unique(state_df$REGION)] <- list(pred)
}
plot_forecast_prophet <- function(state){
plot(
models_profet[[state]],
forecasts_profet[[state]]
)
}
plot_forecast_prophet('Montana')
models_auto_arima    <- list()
forecasts_auto_arima <- list()
counter <-1
for(state_df in train_split){
model <-
auto.arima(
ts(state_df$ILITOTAL,
frequency=52,
start=decimal_date(ymd("2010-10-04")))
)
pred <- forecast(model,h=4)
models_auto_arima[unique(state_df$REGION)] <- list(model)
forecasts_auto_arima[unique(state_df$REGION)] <- list(pred)
}
plot_forecast_prophet('Colorado')
plot_forecast_prophet('New York')
library(tidyverse)
library(ggplot2)
library(scales)
library(lubridate)
library(caret)
library(Matrix)
colorado_weather <- read_csv('input/Colorado-Station-Report.csv') %>%
select(-STATION, -NAME)
ilinet_colorado <- readRDS('data/train.rds') %>%
filter(REGION == 'Colorado')
colorado_weather %>%
select(-DATE) %>%
mutate_all(
funs(rescale, "rescale", rescale(., to = c(0, 1)))
) %>%
select(contains('rescale')) %>%
ts.plot(col = c('blue', 'red', 'green'))
colorado_weather
ilinet_colorado %>%
select(-REGION, -YEAR, -WEEK, -YEARWEEK, -PRETTYDATE) %>%
mutate_all(
funs(rescale, "rescale", rescale(., to = c(0, 1)))
) %>%
select(contains('rescale')) %>%
ts.plot(col = c('blue', 'red', 'green', 'black'))
ilinet_colorado
train <- ilinet_colorado %>%
mutate(
MONTH = lubridate::month(PRETTYDATE)
) %>%
left_join(
colorado_weather %>%
rowwise() %>%
mutate(
YEAR  = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[1]),
MONTH = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[2])
) %>%
select(-DATE),
by = c("YEAR", "MONTH")
) %>%
mutate(
RESPONSE = lead(ILITOTAL, n = 1)
) %>%
select(ILITOTAL, PRCP, SNOW, TAVG, RESPONSE)
test  <- train[391:397, ]
train <- train[1:390, ]
model <- glm(RESPONSE ~ ., data = train)
model
prediction <- as.integer(predict(model, newdata = test[, 1:5]))
# Metrics ----
RMSE(prediction, test$RESPONSE, na.rm = TRUE)
print(prediction)
print(test$RESPONSE)
h2o.init()
library(tidyverse)
library(ggplot2)
library(scales)
library(lubridate)
library(caret)
library(Matrix)
library(h2o)
h2o.init()
y <- "RESPONSE"
x <- setdiff(names(train), y)
h2oFrameTraining=as.h2o(train)
aml <- h2o.automl(x = x, y = y,
training_frame = h2oFrameTraining,
max_runtime_secs = 120)
lb <- aml@leaderboard
lb
library(xgboost)
install.packages('xgboost')
library(xgboost)
dtrain <- xgb.DMatrix(data = data.matrix(train), label= train$RESPONSE)
dtest <- xgb.DMatrix(data = data.matrix(test), label= test$RESPONSE)
modelXg <- xgboost(data = dtrain, # the data
max.depth = 3, # the maximum depth of each decision tree
nround = 10, # number of boosting rounds
early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop
objective = "reg:linear", # the objective function
gamma = 1) # add a regularization term
pred <- predict(modelXg, dtest)
RMSE(pred, test$RESPONSE, na.rm = TRUE)
print(pred)
print(test$RESPONSE)
pred <- as.integer(predict(modelXg, dtest))
RMSE(pred, test$RESPONSE, na.rm = TRUE)
print(pred)
print(test$RESPONSE)
data.frame(predict = pred, true = test$RESPONSE) %>% View
modelXg
prediction <- as.integer(predict(model, newdata = test[, 1:4]))
# Metrics ----
RMSE(prediction, test$RESPONSE, na.rm = TRUE)
print(prediction)
print(test$RESPONSE)
dtrain <- xgb.DMatrix(data = data.matrix(train), label= train$RESPONSE)
dtest <- xgb.DMatrix(data = data.matrix(test[, 1:4]))
pred <- as.integer(predict(modelXg, dtest))
library(tidyverse)
library(ggplot2)
library(scales)
library(lubridate)
library(caret)
library(Matrix)
colorado_weather <- read_csv('input/Colorado-Station-Report.csv') %>%
select(-STATION, -NAME)
ilinet_colorado <- readRDS('data/train.rds') %>%
filter(REGION == 'Colorado')
ilinet_arima <- readRDS('data/forecasts_arima.rds')
ilinet_arima$Colorado
ilinet_arima$Colorado$fitted
colorado_weather <- read_csv('input/Colorado-Station-Report.csv') %>%
select(-STATION, -NAME)
ilinet_colorado <- readRDS('data/train.rds') %>%
filter(REGION == 'Colorado')
ilinet_arima <- readRDS('data/forecasts_arima.rds')$Colorado$fitted
colorado_weather %>%
select(-DATE) %>%
mutate_all(
funs(rescale, "rescale", rescale(., to = c(0, 1)))
) %>%
select(contains('rescale')) %>%
ts.plot(col = c('blue', 'red', 'green'))
colorado_weather %>%
select(-DATE) %>%
mutate_all(
funs(rescale, "rescale", rescale(., to = c(0, 1)))
) %>%
select(contains('rescale')) %>%
ts.plot(col = c('blue', 'red', 'green'))
colorado_weather
ilinet_colorado %>%
select(-REGION, -YEAR, -WEEK, -YEARWEEK, -PRETTYDATE) %>%
mutate_all(
funs(rescale, "rescale", rescale(., to = c(0, 1)))
) %>%
select(contains('rescale')) %>%
ts.plot(col = c('blue', 'red', 'green', 'black'))
ilinet_colorado
train <- ilinet_colorado %>%
mutate(
MONTH = lubridate::month(PRETTYDATE)
) %>%
bind_cols(as.tibble(ilinet_arima)) %>%
left_join(
colorado_weather %>%
rowwise() %>%
mutate(
YEAR  = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[1]),
MONTH = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[2])
) %>%
select(-DATE),
by = c("YEAR", "MONTH")
) %>%
mutate(
RESPONSE = lead(ILITOTAL, n = 1)
) %>%
select(ILITOTAL, PRCP, SNOW, TAVG, RESPONSE)
train <- ilinet_colorado %>%
mutate(
MONTH = lubridate::month(PRETTYDATE)
) %>%
bind_cols(as.tibble(ilinet_arima))
train <- ilinet_colorado %>%
mutate(
MONTH = lubridate::month(PRETTYDATE)
) %>%
bind_cols(ARIMA = as.tibble(ilinet_arima))
train <- ilinet_colorado %>%
mutate(
MONTH = lubridate::month(PRETTYDATE)
) %>%
bind_cols(as.tibble(ilinet_arima)) %>%
left_join(
colorado_weather %>%
rowwise() %>%
mutate(
YEAR  = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[1]),
MONTH = as.integer(str_split(DATE, pattern = '-', simplify = TRUE)[2])
) %>%
select(-DATE),
by = c("YEAR", "MONTH")
) %>%
mutate(
RESPONSE = lead(ILITOTAL, n = 1)
) %>%
select(ILITOTAL, PRCP, SNOW, TAVG, ARIMA = x, RESPONSE)
test  <- train[391:397, ]
test  <- train[391:397, ]
train <- train[1:390, ]
model <- glm(RESPONSE ~ ., data = train)
model
prediction <- as.integer(predict(model, newdata = test[, 1:5]))
# Metrics ----
RMSE(prediction, test$RESPONSE, na.rm = TRUE)
print(prediction)
print(test$RESPONSE)
library(xgboost)
dtrain <- xgb.DMatrix(data = data.matrix(train), label= train$RESPONSE)
dtest <- xgb.DMatrix(data = data.matrix(test), label= test$RESPONSE)
modelXg <- xgboost(data = dtrain, # the data
max.depth = 3, # the maximum depth of each decision tree
nround = 10, # number of boosting rounds
early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop
objective = "reg:linear", # the objective function
gamma = 1) # add a regularization term
pred <- predict(modelXg, dtest)
RMSE(pred, test$RESPONSE, na.rm = TRUE)
print(pred)
print(test$RESPONSE)
pred <- as.integer(predict(modelXg, dtest))
RMSE(pred, test$RESPONSE, na.rm = TRUE)
print(pred)
print(test$RESPONSE)
test$ARIMA
modelXg <- xgboost(data = dtrain, # the data
max.depth = 3, # the maximum depth of each decision tree
nround = 20, # number of boosting rounds
early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop
objective = "reg:linear", # the objective function
gamma = 1) # add a regularization term
pred <- as.integer(predict(modelXg, dtest))
RMSE(pred, test$RESPONSE, na.rm = TRUE)
print(pred)
print(test$RESPONSE)
modelXg <- xgboost(data = dtrain, # the data
max.depth = 3, # the maximum depth of each decision tree
nround = 5, # number of boosting rounds
early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop
objective = "reg:linear", # the objective function
gamma = 1) # add a regularization term
pred <- as.integer(predict(modelXg, dtest))
RMSE(pred, test$RESPONSE, na.rm = TRUE)
print(pred)
print(test$RESPONSE)
modelXg <- xgboost(data = dtrain, # the data
max.depth = 3, # the maximum depth of each decision tree
nround = 10, # number of boosting rounds
early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop
objective = "reg:linear", # the objective function
gamma = 1) # add a regularization term
